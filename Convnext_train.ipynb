{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.utils\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "UWSl2_e89B7i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Classification/Required/'\n",
        "len(os.listdir(path+'No Defect')), len(os.listdir(path+'Foreign'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvNsU7-kUyK0",
        "outputId": "43a0adf9-05ac-42a3-fd93-4d1fb61643ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1725, 13369)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Classification/classfication final data 1st nov.zip'"
      ],
      "metadata": {
        "id": "8oNt-SkCWdrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_name = 'convnext_small'\n",
        "model = models.__dict__[cnn_name](True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRTB-BW2UyNL",
        "outputId": "35014a66-fbb2-4957-fddc-e71964939c74"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Small_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier[2] = nn.Linear(in_features=768, out_features=10, bias=True)"
      ],
      "metadata": {
        "id": "YkRTrbA0UyPU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Setup"
      ],
      "metadata": {
        "id": "QCkVL1KoX7Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "\n",
        "config = dict(\n",
        "    saved_path=\"/content/drive/MyDrive/Classification/convnext_small.pt\",\n",
        "    best_saved_path = \"/content/drive/MyDrive/Classification/convnext_small_best.pt\",\n",
        "    lr=0.001,\n",
        "    EPOCHS = 40,\n",
        "    BATCH_SIZE = 32,\n",
        "    IMAGE_SIZE = 224,\n",
        "    TRAIN_VALID_SPLIT = 0.2,\n",
        "    device=device,\n",
        "    SEED = 42,\n",
        "    pin_memory=True,\n",
        "    num_workers=3,\n",
        "    USE_AMP = True,\n",
        "    channels_last=False)\n",
        "\n",
        "random.seed(config['SEED'])\n",
        "# If you or any of the libraries you are using rely on NumPy, you can seed the global NumPy RNG\n",
        "np.random.seed(config['SEED'])\n",
        "# Prevent RNG for CPU and GPU using torch\n",
        "torch.manual_seed(config['SEED'])\n",
        "torch.cuda.manual_seed(config['SEED'])\n",
        "\n",
        "torch.backends.cudnn.benchmarks = True\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "#torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
        "#torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "data_transforms = {\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKslW5RiXLo8",
        "outputId": "34f93da9-4583-48ae-f221-72bde9c3583f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_path = '/content/classfication final data'\n",
        "\n",
        "data = torchvision.datasets.ImageFolder(root=my_path,transform=data_transforms['test'])\n",
        "print(len(data))\n",
        "train_data,test_data,valid_data = torch.utils.data.dataset.random_split(data,[120000,1615,30000])\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(dataset=train_data,batch_size=config['BATCH_SIZE'],shuffle=True, num_workers = config['num_workers'],\n",
        "                                          pin_memory = config['pin_memory'])\n",
        "valid_dl = torch.utils.data.DataLoader(dataset = valid_data,batch_size=config['BATCH_SIZE'],shuffle=True, num_workers =\n",
        "                                          config['num_workers'], pin_memory = config['pin_memory'])\n",
        "test_dl = torch.utils.data.DataLoader(dataset=test_data,batch_size=config['BATCH_SIZE'],shuffle=True, num_workers = config['num_workers'],\n",
        "                                          pin_memory = config['pin_memory'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgWXtRFxXLsV",
        "outputId": "9e2b3541-559b-4260-c74c-d11feb001775"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Am2LreFMXLyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "model = model.to(config['device'])\n",
        "optimizer = optim.Adam(model.parameters(),lr=config['lr'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train_model(model,criterion,optimizer,num_epochs=10):\n",
        "\n",
        "    since = time.time()\n",
        "    batch_ct = 0\n",
        "    example_ct = 0\n",
        "    best_acc = 0.3\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 25)\n",
        "        run_corrects = 0\n",
        "        #Training\n",
        "        model.train()\n",
        "        for x,y in train_dl: #BS=32 ([BS,3,224,224], [BS,4])\n",
        "            if config['channels_last']:\n",
        "                x = x.to(config['device'], memory_format=torch.channels_last) #CHW --> #HWC\n",
        "            else:\n",
        "                x = x.to(config['device'])\n",
        "            y = y.to(config['device']) #CHW --> #HWC\n",
        "\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            #optimizer.zero_grad(set_to_none=True)\n",
        "            ######################################################################\n",
        "\n",
        "            train_logits = model(x) #Input = [BS,3,224,224] (Image) -- Model --> [BS,4] (Output Scores)\n",
        "\n",
        "            _, train_preds = torch.max(train_logits, 1)\n",
        "            train_loss = criterion(train_logits,y)\n",
        "            train_loss = criterion(train_logits,y)\n",
        "            run_corrects += torch.sum(train_preds == y.data)\n",
        "\n",
        "            train_loss.backward() # Backpropagation this is where your W_gradient\n",
        "            loss=train_loss\n",
        "\n",
        "            optimizer.step() # W_new = W_old - LR * W_gradient\n",
        "            example_ct += len(x)\n",
        "            batch_ct += 1\n",
        "            if ((batch_ct + 1) % 700) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "            ########################################################################\n",
        "\n",
        "        #validation\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        total = 0\n",
        "        # Disable gradient calculation for validation or inference using torch.no_rad()\n",
        "        with torch.no_grad():\n",
        "            for x,y in valid_dl:\n",
        "                if config['channels_last']:\n",
        "                    x = x.to(config['device'], memory_format=torch.channels_last) #CHW --> #HWC\n",
        "                else:\n",
        "                    x = x.to(config['device'])\n",
        "                y = y.to(config['device'])\n",
        "                valid_logits = model(x)\n",
        "                _, valid_preds = torch.max(valid_logits, 1)\n",
        "                valid_loss = criterion(valid_logits,y)\n",
        "                running_loss += valid_loss.item() * x.size(0)\n",
        "                running_corrects += torch.sum(valid_preds == y.data)\n",
        "                total += y.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(valid_data)\n",
        "        epoch_acc = running_corrects.double() / len(valid_data)\n",
        "        train_acc = run_corrects.double() / len(train_data)\n",
        "        print(\"Train Accuracy\",train_acc.cpu())\n",
        "        print(\"Validation Loss is {}\".format(epoch_loss))\n",
        "        print(\"Validation Accuracy is {}\\n\".format(epoch_acc.cpu()))\n",
        "        if epoch_acc.cpu()>best_acc:\n",
        "            print('One of the best validation accuracy found.\\n')\n",
        "            torch.save(model.state_dict(), config['best_saved_path'])\n",
        "            best_acc = epoch_acc.cpu()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    torch.save(model.state_dict(), config['saved_path'])\n",
        "\n",
        "\n",
        "def train_log(loss, example_ct, epoch):\n",
        "    loss = float(loss)\n",
        "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "u0tycoy_WMDU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "XrmPmZ2AZgwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, criterion, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SvYiKDeY-CG",
        "outputId": "871502b7-7199-4544-b23d-33cfdf4a53f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "-------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8YefIKyGY-Dt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}